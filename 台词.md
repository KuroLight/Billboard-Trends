Hi, everyone 

Motivation

In this project, we are going to investigate the music trends of the billboard hot-100 charts from year 1950~2018. 

During the recent half a century, song styles in the U.S., especially lyrics, have kept changing over the years. Thus, we are more insterested in learning about the trends behind the lyrics rather than trends behind artists or titles(song names). 

Specifically, we looked at the differences among word count, average number of vocabulary of all songs and sentimental words for each decade.

Overall, 5 main parts are included in our project:
1. Data collection
2. Data preprocessing
3. Lyrics Words Analysis
4. Sentimental Analysis
5. Visualization


## yongfat
### scraper
During data collection, there are two seperate sub-processes.

first things first, 

we have to get charts data from billboard.com. Simply we use requests to get the website data and BeautifulSoup to parse charts of songs.

Then, 

with the list of songs, including song titles and artist names, we can request for structural lyrics via Genius.com while it provides us with simple but powerful ReSTful APIs.

Before analysis, we have used some NLP techniques to preprocess the raw data we have, such as removing stopwords, tokenizing and stemming sentences.

## shiyao li

Song vocabulary of lyrics is a representation of how many unique words are used in a song. The more varied a vocabulary a text possesses, the higher its lexical diversity. 

First of all, we found that the average unique words per song are increasing over the years. Plus, we have studied the total count of nouns and adjectives in songs. (补充：对于这个趋势的理解，分析和意义)

Second, we have also looked into the data of artists. We have ranked artists with the most songs on hot-100 as well as with the most unique words in their songs. （哪些歌手职业生涯比较长久）

Third, the most repeated words are also ranked out of the whole words along 70 years. （ 流行词 排行榜 // decades趋势?）

After all, we have a glance into the actual song data. After performing some conditioning such as data cleansing and removing uninformative words, we have done an exploratory analysis at the song level.

## boyu liu

Now we step into another level. We have delve deeper into text mining by unnesting lyrics into tokenized words for lyrical complexity. The results shows us critical insights for the next steps of sentimental
 analysis and topic modeling.

In this part, we explore a simple implementation of the NLP technique known as sentiment analysis, which attempts to quantify the tonal properties of a text dataset. This is done using the TextBlob library, and is applied to the 'A Million News Headlines' dataset – a corpus of over one million news article headlines published by the ABC.

We now run the TextBlob sentiment function on every lyrics, and use it to construct a new series for both subjectivity and polarity.

Evidently there have been distinct changes across both series! Over the recent half a century, we can see that people love more and more negative sentimental songs than before.

# cluster:

We use a clustering algorithm to better understand the hidden structure within the lyrics with a TF-IDF matrix. Here we choose K-Means with a predetermined number 5 of clusters. Each observation is assigned to a cluster so that it can minimize the within cluster sum of squares.

Multidimensional scaling (MDS) is a form of non-linear dimensionality reduction. We use MDS to convert our matrix into 2D matrix. 
https://en.wikipedia.org/wiki/Multidimensional_scaling One alternative is PCA(principal component analysis). 

Finally, we plot our lyrics clustering using matplotlib. 